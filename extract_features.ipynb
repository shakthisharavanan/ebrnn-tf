{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "import pylab as plt\n",
    "\n",
    "from tqdm import tqdm, trange, tqdm_notebook, tnrange\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import pickle as pkl\n",
    "import subprocess as sp\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_dir = \"/mnt/workspace/models/research/slim/\"\n",
    "sys.path.insert(0, slim_dir)\n",
    "from nets import vgg\n",
    "image_size = vgg.vgg_16.default_image_size\n",
    "# print(image_size)\n",
    "\n",
    "from preprocessing import vgg_preprocessing\n",
    "\n",
    "dataset_dir = \"/mnt/workspace/datasets/UCF-101/\"\n",
    "label_dir = \"/mnt/workspace/datasets/ucf101/ucf24/labels/\"\n",
    "batch_size = 16\n",
    "checkpoints_dir = \"/mnt/workspace/models/checkpoints/\"\n",
    "extracted_features_dir = \"/mnt/workspace/ebrnn-tf/extracted_features/\"\n",
    "\n",
    "# means = [123.68, 116.779, 103.939]\n",
    "means = [103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(16, 240, 320, 3), dtype=uint8)\n",
      "Tensor(\"Softmax:0\", shape=(16, 1000), dtype=float32)\n",
      "Tensor(\"vgg_16/fc7/Relu:0\", shape=(16, 1, 1, 4096), dtype=float32)\n",
      "Tensor(\"vgg_16/conv5/conv5_3/Relu:0\", shape=(16, 14, 14, 512), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /mnt/workspace/models/checkpoints/vgg_16.ckpt\n"
     ]
    }
   ],
   "source": [
    "slim = tf.contrib.slim\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    input_batch = tf.placeholder(dtype=tf.uint8, shape=(batch_size,240,320,3))\n",
    "    print(input_batch)\n",
    "\n",
    "    resized_images = tf.image.resize_images(input_batch, [image_size,image_size])\n",
    "    channels = tf.split(axis=3, num_or_size_splits=3, value=resized_images)\n",
    "    for j in range(3):\n",
    "        channels[j] -= means[j]\n",
    "    normalized_images = tf.concat(axis=3, values=channels)\n",
    "    \n",
    "    with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "        outputs, end_points = vgg.vgg_16(normalized_images,num_classes=1000, is_training=False)\n",
    "        final_conv = end_points['vgg_16/conv5/conv5_3']\n",
    "        fc7 = end_points['vgg_16/fc7']\n",
    "        probablities = tf.nn.softmax(outputs)\n",
    "        print(probablities)\n",
    "        print(fc7)\n",
    "        print(final_conv)\n",
    "    init_fn = slim.assign_from_checkpoint_fn(os.path.join(checkpoints_dir, 'vgg_16.ckpt'),slim.get_model_variables('vgg_16'))\n",
    "    sess = tf.Session()\n",
    "    init_fn(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(path):\n",
    "    command = [ 'ffmpeg',\n",
    "    #            '-i', '/mnt/workspace/datasets/UCF-101/BreastStroke/v_BreastStroke_g01_c01.avi',\n",
    "    #             '-i', '/mnt/workspace/datasets/UCF-101/BasketballDunk/v_BasketballDunk_g01_c01.avi',\n",
    "               '-i', '/mnt/workspace/datasets/UCF-101/Basketball/v_Basketball_g01_c03.avi',\n",
    "    #            '-i', '/mnt/workspace/datasets/UCF-101/Billiards/v_Billiards_g01_c01.avi',\n",
    "                '-f', 'image2pipe',\n",
    "                '-pix_fmt', 'rgb24',\n",
    "                '-vcodec', 'rawvideo', '-']\n",
    "    pipe = sp.Popen(command, stdout = sp.PIPE, bufsize=10**8)\n",
    "    video_frames = []\n",
    "    while True:\n",
    "        # read 420*360*3 bytes (= 1 frame)\n",
    "        raw_image = pipe.stdout.read(240*320*3)\n",
    "    #     print(type(raw_image))\n",
    "        if len(raw_image) != 240*320*3:\n",
    "            break;\n",
    "        # transform the byte read into a numpy array\n",
    "        image =  np.fromstring(raw_image, dtype='uint8')\n",
    "        image = image.reshape((240,320,3))\n",
    "    #     image[:,:,0] = image[:,:,0] - 123.68\n",
    "    #     image[:,:,1] = image[:,:,1] - 116.78\n",
    "    #     image[:,:,2] = image[:,:,2] - 103.94\n",
    "        video_frames.append(image)\n",
    "        # throw away the data in the pipe's buffer.\n",
    "        pipe.stdout.flush()\n",
    "    #     np.shape(image)\n",
    "    #     plt.imshow(image)\n",
    "    video_frames = np.asarray(video_frames, dtype=np.uint8)\n",
    "    return video_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(video_path):\n",
    "    \n",
    "    video_frames = read_video(video_path)\n",
    "#     print(np.shape(video_frames))\n",
    "    file_length = np.shape(video_frames)[0]\n",
    "    with h5py.File((extracted_features_dir + \"{}.h5\").format(video_path), \"w\") as f:\n",
    "        dset = f.create_dataset()\n",
    "        for start, end in zip(range(0, file_length, batch_size),range(batch_size, file_length + batch_size, batch_size)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [x.replace(label_dir,\"\") for x in sorted(glob.glob(label_dir+\"*\"))]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for i in tnrange(len(labels), desc='Total progress'):\n",
    "    all_videos = sorted(glob.glob(dataset_dir+labels[i]+\"/*\"))\n",
    "    for j in tnrange(len(all_videos), desc=labels[i], leave=False):\n",
    "        video_path = all_videos[j]\n",
    "#         video_frames = read_video(video_path)\n",
    "        features = extract_features(video_path)\n",
    "#         sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start, end in zip(range(0, video_frames.shape[0] + batch_size, batch_size),\n",
    "                      range(batch_size, video_frames.shape[0] + batch_size, batch_size)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import imagenet\n",
    "names = imagenet.create_readable_names_for_imagenet_labels()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((16, 720, 1280, 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(a))\n",
    "print(np.shape(video_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames = video_frames[:16,:,:,:]\n",
    "probablities_batch, feats = sess.run([probablities, fc7], feed_dict={input_batch: video_frames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(probablities_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    max_value = max(probablities_batch[i])\n",
    "#     print(max_value)\n",
    "    print(list(probablities_batch[i]).index(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = probablities_batch[0, 0:]\n",
    "sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), key=lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import imagenet\n",
    "names = imagenet.create_readable_names_for_imagenet_labels()\n",
    "for i in range(5):\n",
    "    index = sorted_inds[i]\n",
    "    # Shift the index of a class name by one. \n",
    "    print('Probability %0.2f%% => [%s]' % (probabilities[index] * 100, names[index+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
